{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKXNjhiaxxUi"
   },
   "source": [
    "# Fundamentals of Machine Learning (CSCI-UA.473)\n",
    "\n",
    "## Homework 2\n",
    "### Due: October 26th, 2023 at 11:59PM\n",
    "\n",
    "### Name: (your name goes here)\n",
    "### Email: (your NYU email goes here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AVL473j7W0CB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Use the same dataset that was released with HW1\n",
    "data = pd.read_csv('hw1_dataset.csv')\n",
    "# Separate the features, target values, and feature names\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oD2ESfcW7ai7"
   },
   "source": [
    "### Question 1: Maximum Likelihood Estimation (MLE) vs Maximum A Posteriori (MAP) (25 points)\n",
    "\n",
    "In Homework 1, we performed linear and ridge regression. To summarize:\n",
    "\n",
    "In Linear regression,\n",
    "\n",
    "$$\\beta = \\arg\\min_{\\beta}\\sum\\left(y_i - \\left(\\beta_0 + \\beta_1 x_{1i} +, \\ldots, + \\beta_px_{p i}\\right)\\right)^2$$\n",
    "\n",
    "\n",
    "* $J(\\beta)$ is the cost function.\n",
    "* $\\beta_0,\\ldots,\\beta_p$ are the coefficients for the features.\n",
    "* $x_{1i}$ represents the values of the feature for the i-th observation.\n",
    "* $y_i$ is the target value for the i-th observation.\n",
    "\n",
    "For ridge regression\n",
    "\n",
    "$$J(\\beta) = \\sum\\left(y_i - \\left(\\beta_0 + \\beta_1 x_{1i} +, \\ldots, + \\beta_px_{p i}\\right)\\right)^2 + \\lambda \\cdot \\sum \\beta_i^2$$\n",
    "\n",
    "* $\\lambda$ is the regularization hyper-parameter.\n",
    "\n",
    "**Task 1.1 (5 points)** Linear regression embodies Maximum Likelihood Estimation (MLE). Show that a closed form expression is $$\\beta = (\\mathbf{A}^\\top \\mathbf{A})^{-1}\\mathbf{A}^\\top \\mathbf{Y}$$ where $\\mathbf{A} = [X_1,\\ldots,X_n]$ and $\\mathbf{Y} = [Y_1,\\ldots,Y_n]$.\n",
    "\n",
    "**Task 1.2 (5 points)**: Ridge regression embodies Maximum A Posteriori (MAP), wherein the regularizer serves as the prior. Show that a closed form expression for the ridge estimator is $$\\beta = (\\mathbf{A}^\\top \\mathbf{A} + \\lambda I)^{-1}\\mathbf{A}^\\top \\mathbf{Y}$$ where $\\mathbf{A} = [X_1,\\ldots,X_n]$ and $\\mathbf{Y} = [Y_1,\\ldots,Y_n]$.\n",
    "\n",
    "**Task 1.3 Implementation (10 points):** Fill in the code below to differentiate between MLE and MAP.\n",
    "\n",
    "**Task 1.4 (5 points):**\n",
    "* Do MLE and MAP yield distinct solutions as the sample size tends to infinity? Explain your answer.\n",
    "\n",
    "* Will the impact of prior be greater with a small or large sample size, and what is the underlying rationale for this phenomenon?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oleMgs0V7Zsl"
   },
   "outputs": [],
   "source": [
    "def mle_linear_regression(X, y):\n",
    "    # Compute the MLE estimates using closed-form solution (HINT: Use np.linalg.inv)\n",
    "\n",
    "    return theta_mle\n",
    "\n",
    "# Calculate MLE estimates without bias\n",
    "theta_mle = mle_linear_regression(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_preds =\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse_mle = np.mean((y_test - y_preds)**2)\n",
    "print(f\"MSE using MLE: {mse_mle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqvfD-8uF-Jl"
   },
   "outputs": [],
   "source": [
    "def map_linear_regression(X, y, lambda_reg):\n",
    "    # Compute MAP estimates with L2 regularization\n",
    "\n",
    "    return theta_map\n",
    "\n",
    "# Set the regularization parameter (lambda)\n",
    "lambda_reg = 0.01\n",
    "theta_map = map_linear_regression(X_train, y_train, lambda_reg)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_preds =\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse_map = np.mean((y_test - y_preds)**2)\n",
    "print(f\"MSE using MAP: {mse_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwH8gND4XGvE"
   },
   "source": [
    "### Question 2: Classification with imbalanced dataset (20 points)\n",
    "\n",
    "We are creating an imbalanced version of the target variable for the Z dataset. An imbalanced dataset means that one class is much more frequent than the other class. In our case, we will consider the two classes as follows:\n",
    "\n",
    "- Class 0: Z progression values that are below the 75th percentile of the original target variable.\n",
    "- Class 1: Z progression values that are above the 75th percentile of the original target variable.\n",
    "\n",
    "By doing this, we are creating an imbalance where Class 0 will be more prevalent than Class 1, mimicking a common scenario in real-world imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQMA6OPsXD49"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle the data\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# Create an imbalanced target variable\n",
    "y_imbalanced = np.where(y > np.percentile(y, 75), 1, 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_imbalanced, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJiy4EyUYX93"
   },
   "source": [
    "\n",
    "**Task 2.1 (3 points):**\n",
    "- Create a SVM classifier with a linear kernel, then calculate accuracy, precision, recall, and F1 score using available library functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKLZyXkwSDw0"
   },
   "outputs": [],
   "source": [
    "### Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6mJ3w9TbWHT"
   },
   "source": [
    "\n",
    "**Task 2.2 (5 points):** What causes the metrics to exhibit lower values for the imbalanced dataset compared to those in homework 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPYn44O40aKX"
   },
   "source": [
    "**Random oversampling** is one of the many techniques used to address the class imbalance problem. It involves increasing the number of instances in the minority class by randomly duplicating existing instances. This helps to balance the class distribution and can lead to improved performance for certain models.\n",
    "\n",
    "**Task 2.3 (2 points):** Calculate and display the following statistics for the target variable (y) before applying random oversampling:\n",
    "  - Mean\n",
    "  - Standard Deviation\n",
    "  - Minimum\n",
    "  - Maximum\n",
    "\n",
    "**Task 2.4 (5 points):** Perform random oversampling on the training set. After oversampling, calculate and display the same statistics for the oversampled target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PItrNXNsX7ou"
   },
   "outputs": [],
   "source": [
    "# Apply Random Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oel3kCeV2tOM"
   },
   "source": [
    "**Task 2.5 (5 points):**\n",
    "- Create another instance of SVM classifier with linear kernel, fit it on the oversampled data and calculate all the prior metrics for the oversampled model.\n",
    "- Show the metrics with different regularization parameters {0.1, 1, 10, 100} on the linear kernel.\n",
    "- Show the metrics with polynomial degrees {-1, 0, 3, 4} and observe how the model's complexity changes.\n",
    "- Introduce different values for the regularization parameter in the RBF kernel and show how it balances the trade-off between maximizing the margin and minimizing classification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeictOez24d9"
   },
   "outputs": [],
   "source": [
    "### Add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oquatEvqroqa"
   },
   "source": [
    "### Question 3: Naive Bayes Model (10 points)\n",
    "\n",
    "Implement the Naieve Bayes classifer on the Z dataset. \n",
    "\n",
    "We will assume that each continuous feature $X_i$ of $X$ follow a Gaussian distribution within each class $Y$.\n",
    "\n",
    "- For each class $c$, calculate the mean $(\\mu_c)$ and standard deviation $(\\sigma_c)$ for each feature. These parameters represent the central tendency and spread of the feature values within each class. They can be computed as:\n",
    "\n",
    "   \\begin{align*}\n",
    "   \\mu_c^j &= \\frac{1}{N_c} \\sum_{i=1}^{N_c} X_i^j \\quad \\text{(mean of feature \\(j\\) in class \\(c\\))} \\\\\n",
    "   \\sigma_c^j &= \\sqrt{\\frac{1}{N_c} \\sum_{i=1}^{N_c} (X_i^j - \\mu_c^j)^2} + \\epsilon \\quad \\text{(standard deviation of feature \\(j\\) in class \\(c\\))}\n",
    "   \\end{align*}\n",
    "     \n",
    "   where $N_c$ is the number of data points in class $c$, and $\\varepsilon=1e^{-6}$ is a small constant added for numerical stability.\n",
    "\n",
    "- To make a prediction for a new data point $x$, calculate the probability of $x$ belonging to each class $c$ using the Gaussian probability density function:\n",
    "\n",
    "   \\begin{align*}\n",
    "   P(X^j = x^j | Y = c) = \\frac{1}{\\sqrt{2\\pi}\\sigma_c^j} e^{-\\frac{1}{2}\\left(\\frac{x^j - \\mu_c^j}{\\sigma_c^j}\\right)^2}\n",
    "   \\end{align*}\n",
    "\n",
    "- Calculate the class probability $P(Y = c | X = x)$ as the product of the probabilities of each feature:\n",
    "\n",
    "    \\begin{align*}\n",
    "     P(Y = c | X = x) = P(Y = c) \\prod_{j=1}^{D} P(X^j = x^j | Y = c)\n",
    "    \\end{align*}\n",
    "\n",
    "   where $D$ is the number of features.\n",
    "\n",
    "- Assign the class label to the class with the highest probability:\n",
    "\n",
    "    \\begin{align*}\n",
    "     \\hat{Y} = \\arg\\max_{c} P(Y = c | X = x)\n",
    "     \\end{align*}\n",
    "\n",
    "**Hint:** In the code for Gaussian Naive Bayes, we take logarithms in certain calculations. This is a common technique used to avoid numerical underflow, especially when working with small probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEIVwXWKrscC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GaussianNaiveBayes:\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.parameters = {}\n",
    "        for c in self.classes:\n",
    "            ### Compute the parameters here\n",
    "\n",
    "    def _calculate_likelihood(self, x, mean, std):\n",
    "        ### Compute the likelihood\n",
    "        return\n",
    "\n",
    "    def _calculate_class_probability(self, x, c):\n",
    "        ### Calculate P(Y = c | X = x)\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        ### Code for predicting the class label\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = np.mean(y_pred == y)\n",
    "        return accuracy\n",
    "\n",
    "# Initialize and train the Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNaiveBayes()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "accuracy = gnb.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4czskeTTCMam"
   },
   "source": [
    "### Question 4: ROC curve and AUROC (15 points)\n",
    "\n",
    "**Task 4.1 (3 points):** Imagine you are a public health researcher investigating the performance of a new diagnostic test for disease Z, which is a potentially life-threatening condition. The test is designed to identify individuals who have the disease. You have collected data from a group of 500 patients who were tested for disease Z, and the results are as follows:\n",
    "\n",
    "Out of 150 patients who actually have disease Z, the test correctly identified 120 of them as positive.\n",
    "However, the test also falsely identified 50 patients who do not have disease Z as positive.\n",
    "\n",
    "* **Precision:** Define precision in the context of this diagnostic test for disease Z. Calculate the precision of the test based on the provided data.\n",
    "* **Recall:** Explain what recall means in this scenario. Calculate the recall of the test based on the provided data.\n",
    "* **F1-score:** Define the F1-score and explain why it is important, especially in the context of diagnosing a serious disease like Z. Calculate the F1-score of the test based on the provided data.\n",
    "* **Specificity:** What is specificity, and why is it relevant when evaluating a diagnostic test like this one? Calculate the specificity of the test based on the provided data.\n",
    "* **Balanced Accuracy:** Describe what balanced accuracy is and why it might be a useful metric in this situation. Calculate the balanced accuracy of the test based on the provided data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPOZo4QM5V_y"
   },
   "source": [
    "**Task 4.2 (6 Points)** Plot the ROC curve\n",
    "\n",
    "An ROC curve plots TPR (y-axis) vs. FPR (x-axis) at all classification thresholds. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives.\n",
    "\n",
    "See this for more details (https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)\n",
    "\n",
    "Plot the ROC curve for Disease Z HW1 dataset with SVM classifier. **Note that you are not allowed to use any library function to compute the ROC. You have to do it from scratch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZnZs_QC5oxQ"
   },
   "outputs": [],
   "source": [
    "## Your code to compute and plot ROC goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9sRjUMk592y"
   },
   "source": [
    "**Task 4.3 (6 Points):** Compute the AUC of ROC\n",
    "\n",
    "AUC stands for \"Area under the ROC Curve.\" That is, AUC measures the entire two-dimensional area underneath the entire ROC curve (think integral calculus) from (0,0) to (1,1). AUC provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example.\n",
    "\n",
    "Compute the AUC of your SVM model. **Note that you are not allowed to use any library function to compute the AUC. You have to do it from scratch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOBw8ACA587S"
   },
   "outputs": [],
   "source": [
    "## Your code to compute the AUC goes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
